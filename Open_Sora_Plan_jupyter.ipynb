{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansorbansor/Chiaki/blob/main/Open_Sora_Plan_jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138abad3-c9e8-4e83-8f75-bc00ea635a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Open-Sora-Plan-v1.0.0-hf'...\n",
            "remote: Enumerating objects: 373, done.\u001b[K\n",
            "remote: Counting objects: 100% (373/373), done.\u001b[K\n",
            "remote: Compressing objects: 100% (268/268), done.\u001b[K\n",
            "remote: Total 373 (delta 93), reused 373 (delta 93), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (373/373), 441.57 KiB | 2.00 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n",
            "Downloading opensora/eval/fvd/styleganv/i3d_torchscript.pt (51 MB)\n",
            "Error downloading object: opensora/eval/fvd/styleganv/i3d_torchscript.pt (bec6519): Smudge error: Error downloading opensora/eval/fvd/styleganv/i3d_torchscript.pt (bec6519f66ea534e953026b4ae2c65553c17bf105611c746d904657e5860a5e2): [bec6519f66ea534e953026b4ae2c65553c17bf105611c746d904657e5860a5e2] Object does not exist on the server: [404] Object does not exist on the server\n",
            "\n",
            "Errors logged to /content/Open-Sora-Plan-v1.0.0-hf/.git/lfs/logs/20250602T062732.787558061.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: opensora/eval/fvd/styleganv/i3d_torchscript.pt: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n",
            "/content/Open-Sora-Plan-v1.0.0-hf\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Cannot install diffusers==0.24.0, gradio==3.50.2 and numpy==2.0.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ðŸš€ STEP 1: Clone repo (SKIP LFS FILES to avoid broken download)\n",
        "%cd /content\n",
        "!GIT_LFS_SKIP_SMUDGE=1 git clone -b dev https://github.com/camenduru/Open-Sora-Plan-v1.0.0-hf\n",
        "%cd /content/Open-Sora-Plan-v1.0.0-hf\n",
        "\n",
        "# ðŸ§© STEP 2: Install dependencies (AVOID numpy 2.0.0 & use newer gradio)\n",
        "!pip install -q diffusers==0.24.0 gradio==4.16.0 einops==0.7.0 omegaconf==2.1.1 \\\n",
        "  pytorch-lightning==1.4.2 torchmetrics==0.6.0 torchtext==0.6 accelerate==0.28.0 \\\n",
        "  \"websockets>=14.0,<15.1.0\"\n",
        "\n",
        "# ðŸ” STEP 3: Restart Runtime after install\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”§ Re-import after restart\n",
        "import os\n",
        "import random\n",
        "import imageio\n",
        "import torch\n",
        "from diffusers import PNDMScheduler\n",
        "from datetime import datetime\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from gradio.components import Textbox, Video, Image\n",
        "from transformers import T5Tokenizer, T5EncoderModel\n",
        "\n",
        "from opensora.models.ae import ae_stride_config, getae, getae_wrapper\n",
        "from opensora.models.diffusion.latte.modeling_latte import LatteT2V\n",
        "from opensora.sample.pipeline_videogen import VideoGenPipeline\n",
        "from opensora.serve.gradio_utils import block_css, title_markdown, randomize_seed_fn, set_env, examples, DESCRIPTION\n",
        "\n",
        "def generate_img(prompt, sample_steps, scale, seed=0, randomize_seed=False, force_images=False):\n",
        "    seed = int(randomize_seed_fn(seed, randomize_seed))\n",
        "    set_env(seed)\n",
        "    video_length = transformer_model.config.video_length if not force_images else 1\n",
        "    height, width = int(args.version.split('x')[1]), int(args.version.split('x')[2])\n",
        "    num_frames = 1 if video_length == 1 else int(args.version.split('x')[0])\n",
        "    with torch.no_grad():\n",
        "        videos = videogen_pipeline(prompt,\n",
        "                                   video_length=video_length,\n",
        "                                   height=height,\n",
        "                                   width=width,\n",
        "                                   num_inference_steps=sample_steps,\n",
        "                                   guidance_scale=scale,\n",
        "                                   enable_temporal_attentions=not force_images,\n",
        "                                   num_images_per_prompt=1,\n",
        "                                   mask_feature=True,\n",
        "                                   ).video\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    videos = videos[0]\n",
        "    tmp_save_path = 'tmp.mp4'\n",
        "    imageio.mimwrite(tmp_save_path, videos, fps=24, quality=9)\n",
        "    display_model_info = f\"Video size: {num_frames}Ã—{height}Ã—{width}, \\nSampling Step: {sample_steps}, \\nGuidance Scale: {scale}\"\n",
        "    return tmp_save_path, prompt, display_model_info, seed\n",
        "\n",
        "# ðŸŒŸ Load Model and Set Args\n",
        "args = type('args', (), {\n",
        "    'ae': 'CausalVAEModel_4x8x8',\n",
        "    'force_images': False,\n",
        "    'model_path': 'LanguageBind/Open-Sora-Plan-v1.0.0',\n",
        "    'text_encoder_name': 'DeepFloyd/t5-v1_1-xxl',\n",
        "    'version': '65x512x512'\n",
        "})\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "# ðŸš€ Load pretrained models\n",
        "transformer_model = LatteT2V.from_pretrained(args.model_path, subfolder=args.version,\n",
        "                                             torch_dtype=torch.float16, cache_dir='cache_dir').to(device)\n",
        "\n",
        "vae = getae_wrapper(args.ae)(args.model_path, subfolder=\"vae\", cache_dir='cache_dir').to(device, dtype=torch.float16)\n",
        "vae.vae.enable_tiling()\n",
        "image_size = int(args.version.split('x')[1])\n",
        "latent_size = (image_size // ae_stride_config[args.ae][1], image_size // ae_stride_config[args.ae][2])\n",
        "vae.latent_size = latent_size\n",
        "transformer_model.force_images = args.force_images\n",
        "tokenizer = T5Tokenizer.from_pretrained(args.text_encoder_name, cache_dir=\"cache_dir\")\n",
        "text_encoder = T5EncoderModel.from_pretrained(args.text_encoder_name, cache_dir=\"cache_dir\",\n",
        "                                              torch_dtype=torch.float16).to(device)\n",
        "\n",
        "# ðŸŽ¯ Set evaluation mode\n",
        "transformer_model.eval()\n",
        "vae.eval()\n",
        "text_encoder.eval()\n",
        "scheduler = PNDMScheduler()\n",
        "videogen_pipeline = VideoGenPipeline(vae=vae,\n",
        "                                     text_encoder=text_encoder,\n",
        "                                     tokenizer=tokenizer,\n",
        "                                     scheduler=scheduler,\n",
        "                                     transformer=transformer_model).to(device=device)\n",
        "\n",
        "# ðŸŽ¨ Gradio Interface\n",
        "demo = gr.Interface(\n",
        "    fn=generate_img,\n",
        "    inputs=[\n",
        "        Textbox(label=\"\", placeholder=\"Please enter your prompt.\"),\n",
        "        gr.Slider(label='Sample Steps', minimum=1, maximum=500, value=50, step=10),\n",
        "        gr.Slider(label='Guidance Scale', minimum=0.1, maximum=30.0, value=10.0, step=0.1),\n",
        "        gr.Slider(label=\"Seed\", minimum=0, maximum=203279, step=1, value=0),\n",
        "        gr.Checkbox(label=\"Randomize seed\", value=True),\n",
        "        gr.Checkbox(label=\"Generate image (1 frame video)\", value=False),\n",
        "    ],\n",
        "    outputs=[\n",
        "        Video(label=\"Vid\", width=512, height=512),\n",
        "        Textbox(label=\"Input Prompt\"),\n",
        "        Textbox(label=\"Model Info\"),\n",
        "        gr.Slider(label='Seed')\n",
        "    ],\n",
        "    title=title_markdown,\n",
        "    description=DESCRIPTION,\n",
        "    theme=gr.themes.Default(),\n",
        "    css=block_css,\n",
        "    examples=examples,\n",
        ")\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "NnURD7MgT3ak",
        "outputId": "2aa84866-4d23-4925-d5bf-a9ea5663bb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ea3bdb5ca37f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPNDMScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from .utils import (\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mDIFFUSERS_SLOW_IMPORT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdoc_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreplace_example_docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdynamic_modules_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_class_from_dynamic_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexport_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_to_gif\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_to_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_to_ply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_to_video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m from .hub_utils import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/utils/dynamic_modules_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_hub_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackaging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'cached_download' from 'huggingface_hub' (/usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}